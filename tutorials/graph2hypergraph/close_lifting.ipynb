{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecule Ring-Based Lifting Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "This notebook imports QM9 dataset and applies a lifting to the molecular representation based on molecular ring information. Then, a neural network is run using the loaded data.\n",
    "\n",
    "As proposed by [Jin et al. (2018)](https://arxiv.org/abs/1802.04364), this implementation aims to condense a molecule ring into a single element. Utilizing the [QM9 dataset](https://paperswithcode.com/dataset/qm9), a benchmark dataset for molecule prediction, we develop a method to treat rings as 2-cell structures by identifying them through the provided SMILES representations of each molecule.\n",
    "\n",
    "Additionally, attributes inspired by those used in [(Battiloro et al., 2024)](https://arxiv.org/abs/2405.15429) are incorporated into the elements, enhancing the representation of the molecule.\n",
    "The attributes are:\n",
    "- **Node**: Atom type, atomic number, and chirality.\n",
    "- **Edge**: Bond type, conjugation and stereochemistry.\n",
    "- **Rings**: Ring size, aromaticity, heteroatoms, saturation, hydrophobicity, electrophilicity, nucleophilicity, and polarity.\n",
    "\n",
    "The notebook is divided into sections:\n",
    "\n",
    "- [Loading the dataset](#loading-the-dataset) loads the config files for the loading QM9 dataset and a ring-based tranformation, creates a dataset object and visualizes it.\n",
    "- [Loading and applying the lifting](#loading-and-applying-the-lifting) defines a simple neural network to test that the lifting creates the expected incidence matrices.\n",
    "- [Create and run a simplicial nn model](#create-and-run-a-simplicial-nn-model) simply runs a forward pass of the model to check that everything is working as expected.\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "Note that for simplicity the notebook is setup to use a simple graph. However, there is a set of available datasets that you can play with.\n",
    "\n",
    "To switch to one of the available datasets, simply change the *dataset_name* variable in [Dataset config](#dataset-config) to one of the following names:\n",
    "\n",
    "* cocitation_cora\n",
    "* cocitation_citeseer\n",
    "* cocitation_pubmed\n",
    "* MUTAG\n",
    "* NCI1\n",
    "* NCI109\n",
    "* PROTEINS_TU\n",
    "* AQSOL\n",
    "* ZINC\n",
    "* QM9\n",
    "\n",
    "With this implementation, also **QM9** is available.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# add ../../ so I can read other modules\n",
    "sys.path.append(\"../../\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this cell any imported module is reloaded before each cell execution\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from modules.data.load.loaders import GraphLoader\n",
    "from modules.data.preprocess.preprocessor import PreProcessor\n",
    "from modules.utils.utils import (\n",
    "    describe_data,\n",
    "    load_dataset_config,\n",
    "    load_model_config,\n",
    "    load_transform_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just need to specify the name of the available dataset that we want to load, in this case, QM9 dataset. First, the dataset config is read from the corresponding yaml file (located at `/configs/datasets/` directory), and then the data is loaded via the implemented `Loaders`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset configuration for UniProt:\n",
      "\n",
      "{'data_domain': 'graph',\n",
      " 'data_type': 'UniProt',\n",
      " 'data_name': 'UniProt',\n",
      " 'data_dir': 'datasets/graph/UniProt',\n",
      " 'query': 'length:[95 TO 155]',\n",
      " 'format': 'tsv',\n",
      " 'fields': 'accession,length',\n",
      " 'size': 500,\n",
      " 'limit': 100,\n",
      " 'threshold': 6.0,\n",
      " 'num_features': 11,\n",
      " 'num_classes': 1,\n",
      " 'task': 'regression',\n",
      " 'loss_type': 'mse',\n",
      " 'monitor_metric': 'mae',\n",
      " 'task_level': 'graph'}\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"UniProt\"\n",
    "dataset_config = load_dataset_config(dataset_name)\n",
    "loader = GraphLoader(dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then access to the data through the `load()`method. \n",
    "\n",
    "Observe that some data points emit warnings, which are due to the fact that the SMILES representation of the molecule is not valid. This is a known issue with the QM9 dataset, and it is not a problem for this tutorial. When loading the dataset, the loader will skip these data points, so they keep excluded for the lifting process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDB file for P47224 already exists.\n",
      "PDB file for Q99471 already exists.\n",
      "PDB file for Q93091 downloaded successfully.\n",
      "PDB file for P62316 already exists.\n",
      "PDB file for Q9HC23 already exists.\n",
      "PDB file for Q16568 already exists.\n",
      "PDB file for G2XKQ0 already exists.\n",
      "PDB file for Q16777 already exists.\n",
      "PDB file for Q9NX01 downloaded successfully.\n",
      "PDB file for O76070 already exists.\n",
      "PDB file for P60866 downloaded successfully.\n",
      "PDB file for P62829 already exists.\n",
      "PDB file for O14907 already exists.\n",
      "PDB file for P01037 already exists.\n",
      "PDB file for P0DPB6 already exists.\n",
      "PDB file for P62277 already exists.\n",
      "PDB file for Q8WVK7 already exists.\n",
      "PDB file for O75956 already exists.\n",
      "PDB file for Q8N9Q2 already exists.\n",
      "PDB file for Q8N100 already exists.\n",
      "PDB file for P56278 already exists.\n",
      "PDB file for P15090 downloaded successfully.\n",
      "PDB file for P55854 already exists.\n",
      "PDB file for P01817 already exists.\n",
      "PDB file for Q9NSK7 already exists.\n",
      "PDB file for P01594 already exists.\n",
      "PDB file for Q9Y2Y1 already exists.\n",
      "PDB file for Q13113 already exists.\n",
      "PDB file for Q07325 downloaded successfully.\n",
      "PDB file for Q6QNY1 downloaded successfully.\n",
      "PDB file for Q96DA6 already exists.\n",
      "PDB file for O43920 already exists.\n",
      "PDB file for P35225 downloaded successfully.\n",
      "PDB file for P03897 downloaded successfully.\n",
      "PDB file for O95166 already exists.\n",
      "PDB file for Q14019 already exists.\n",
      "PDB file for P61353 already exists.\n",
      "PDB file for A6NFY7 already exists.\n",
      "PDB file for P02042 already exists.\n",
      "PDB file for Q9BYD5 downloaded successfully.\n",
      "PDB file for Q9Y6H6 already exists.\n",
      "PDB file for P06307 already exists.\n",
      "PDB file for Q5TA82 already exists.\n",
      "PDB file for P10092 already exists.\n",
      "PDB file for O14796 already exists.\n",
      "PDB file for A6NGQ2 already exists.\n",
      "PDB file for Q9BVM4 already exists.\n",
      "PDB file for P61254 already exists.\n",
      "PDB file for Q9H492 already exists.\n",
      "PDB file for P01742 downloaded successfully.\n",
      "PDB file for P04118 already exists.\n",
      "PDB file for Q9UHA4 downloaded successfully.\n",
      "PDB file for P69891 already exists.\n",
      "PDB file for Q5T752 already exists.\n",
      "PDB file for P83881 already exists.\n",
      "PDB file for P09912 already exists.\n",
      "PDB file for O95214 already exists.\n",
      "PDB file for P53999 already exists.\n",
      "PDB file for Q9Y5T4 already exists.\n",
      "PDB file for Q8WXF3 already exists.\n",
      "PDB file for O14519 already exists.\n",
      "PDB file for Q8N6L1 downloaded successfully.\n",
      "PDB file for O96015 downloaded successfully.\n",
      "PDB file for Q9Y3D7 already exists.\n",
      "PDB file for Q9BRT3 already exists.\n",
      "PDB file for O43676 already exists.\n",
      "PDB file for P01814 already exists.\n",
      "PDB file for Q9Y3E0 downloaded successfully.\n",
      "PDB file for Q53S33 already exists.\n",
      "PDB file for P01848 already exists.\n",
      "PDB file for Q9Y5R8 already exists.\n",
      "PDB file for Q03403 already exists.\n",
      "PDB file for Q86U28 already exists.\n",
      "PDB file for Q8TF09 already exists.\n",
      "PDB file for P01034 already exists.\n",
      "PDB file for P12273 already exists.\n",
      "PDB file for Q15004 already exists.\n",
      "PDB file for O00422 downloaded successfully.\n",
      "PDB file for Q5T753 already exists.\n",
      "PDB file for Q56P42 already exists.\n",
      "PDB file for P68431 already exists.\n",
      "PDB file for P01700 already exists.\n",
      "PDB file for P51397 already exists.\n",
      "PDB file for P53567 already exists.\n",
      "PDB file for Q6UX46 already exists.\n",
      "PDB file for Q03393 already exists.\n",
      "PDB file for O95670 downloaded successfully.\n",
      "PDB file for Q9NRY2 already exists.\n",
      "PDB file for O43768 already exists.\n",
      "PDB file for P63165 already exists.\n",
      "PDB file for P06899 already exists.\n",
      "PDB file for Q16873 already exists.\n",
      "PDB file for P0DJI8 already exists.\n",
      "PDB file for P31151 already exists.\n",
      "PDB file for Q9BUE6 downloaded successfully.\n",
      "PDB file for Q15836 already exists.\n",
      "PDB file for P04141 already exists.\n",
      "PDB file for P61956 already exists.\n",
      "PDB file for Q9BTM9 already exists.\n",
      "PDB file for P0DI82 already exists.\n",
      "PDB file for P47224 already exists.\n",
      "PDB file for Q99471 already exists.\n",
      "PDB file for Q93091 already exists.\n",
      "PDB file for P62316 already exists.\n",
      "PDB file for Q9HC23 already exists.\n",
      "PDB file for Q16568 already exists.\n",
      "PDB file for G2XKQ0 already exists.\n",
      "PDB file for Q16777 already exists.\n",
      "PDB file for Q9NX01 already exists.\n",
      "PDB file for O76070 already exists.\n",
      "PDB file for P60866 already exists.\n",
      "PDB file for P62829 already exists.\n",
      "PDB file for O14907 already exists.\n",
      "PDB file for P01037 already exists.\n",
      "PDB file for P0DPB6 already exists.\n",
      "PDB file for P62277 already exists.\n",
      "PDB file for Q8WVK7 already exists.\n",
      "PDB file for O75956 already exists.\n",
      "PDB file for Q8N9Q2 already exists.\n",
      "PDB file for Q8N100 already exists.\n",
      "PDB file for P56278 already exists.\n",
      "PDB file for P15090 already exists.\n",
      "PDB file for P55854 already exists.\n",
      "PDB file for P01817 already exists.\n",
      "PDB file for Q9NSK7 already exists.\n",
      "PDB file for P01594 already exists.\n",
      "PDB file for Q9Y2Y1 already exists.\n",
      "PDB file for Q13113 already exists.\n",
      "PDB file for Q07325 already exists.\n",
      "PDB file for Q6QNY1 already exists.\n",
      "PDB file for Q96DA6 already exists.\n",
      "PDB file for O43920 already exists.\n",
      "PDB file for P35225 already exists.\n",
      "PDB file for P03897 already exists.\n",
      "PDB file for O95166 already exists.\n",
      "PDB file for Q14019 already exists.\n",
      "PDB file for P61353 already exists.\n",
      "PDB file for A6NFY7 already exists.\n",
      "PDB file for P02042 already exists.\n",
      "PDB file for Q9BYD5 already exists.\n",
      "PDB file for Q9Y6H6 already exists.\n",
      "PDB file for P06307 already exists.\n",
      "PDB file for Q5TA82 already exists.\n",
      "PDB file for P10092 already exists.\n",
      "PDB file for O14796 already exists.\n",
      "PDB file for A6NGQ2 already exists.\n",
      "PDB file for Q9BVM4 already exists.\n",
      "PDB file for P61254 already exists.\n",
      "PDB file for Q9H492 already exists.\n",
      "PDB file for P01742 already exists.\n",
      "PDB file for P04118 already exists.\n",
      "PDB file for Q9UHA4 already exists.\n",
      "PDB file for P69891 already exists.\n",
      "PDB file for Q5T752 already exists.\n",
      "PDB file for P83881 already exists.\n",
      "PDB file for P09912 already exists.\n",
      "PDB file for O95214 already exists.\n",
      "PDB file for P53999 already exists.\n",
      "PDB file for Q9Y5T4 already exists.\n",
      "PDB file for Q8WXF3 already exists.\n",
      "PDB file for O14519 already exists.\n",
      "PDB file for Q8N6L1 already exists.\n",
      "PDB file for O96015 already exists.\n",
      "PDB file for Q9Y3D7 already exists.\n",
      "PDB file for Q9BRT3 already exists.\n",
      "PDB file for O43676 already exists.\n",
      "PDB file for P01814 already exists.\n",
      "PDB file for Q9Y3E0 already exists.\n",
      "PDB file for Q53S33 already exists.\n",
      "PDB file for P01848 already exists.\n",
      "PDB file for Q9Y5R8 already exists.\n",
      "PDB file for Q03403 already exists.\n",
      "PDB file for Q86U28 already exists.\n",
      "PDB file for Q8TF09 already exists.\n",
      "PDB file for P01034 already exists.\n",
      "PDB file for P12273 already exists.\n",
      "PDB file for Q15004 already exists.\n",
      "PDB file for O00422 already exists.\n",
      "PDB file for Q5T753 already exists.\n",
      "PDB file for Q56P42 already exists.\n",
      "PDB file for P68431 already exists.\n",
      "PDB file for P01700 already exists.\n",
      "PDB file for P51397 already exists.\n",
      "PDB file for P53567 already exists.\n",
      "PDB file for Q6UX46 already exists.\n",
      "PDB file for Q03393 already exists.\n",
      "PDB file for O95670 already exists.\n",
      "PDB file for Q9NRY2 already exists.\n",
      "PDB file for O43768 already exists.\n",
      "PDB file for P63165 already exists.\n",
      "PDB file for P06899 already exists.\n",
      "PDB file for Q16873 already exists.\n",
      "PDB file for P0DJI8 already exists.\n",
      "PDB file for P31151 already exists.\n",
      "PDB file for Q9BUE6 already exists.\n",
      "PDB file for Q15836 already exists.\n",
      "PDB file for P04141 already exists.\n",
      "PDB file for P61956 already exists.\n",
      "PDB file for Q9BTM9 already exists.\n",
      "PDB file for P0DI82 already exists.\n",
      "\n",
      "Dataset contains 100 samples.\n",
      "\n",
      "Providing more details about sample 0/100:\n",
      " - Set with 124 points.\n",
      " - Features dimension: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = loader.load()\n",
    "describe_data(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Applying the Lifting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will instantiate the lifting we want to apply to the data. \n",
    "\n",
    "A **ring-based lifting** is applied. Molecule ring information is extracted for each molecule. Then, a 2-cell is assigned to each ring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transform configuration for graph2hypergraph/close_lifting:\n",
      "\n",
      "{'transform_type': 'lifting',\n",
      " 'transform_name': 'HypergraphCloseLifting',\n",
      " 'loop': True,\n",
      " 'feature_lifting': 'ProjectionSum',\n",
      " 'distance': 6.0}\n"
     ]
    }
   ],
   "source": [
    "# Define transformation type and id\n",
    "transform_type = \"liftings\"\n",
    "# If the transform is a topological lifting, it should include both the type of the lifting and the identifier\n",
    "transform_id = \"graph2hypergraph/close_lifting\"\n",
    "\n",
    "# Read yaml file\n",
    "transform_config = {\n",
    "    \"lifting\": load_transform_config(transform_type, transform_id)\n",
    "    # other transforms (e.g. data manipulations, feature liftings) can be added here\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We than apply the transform via our `PreProcesor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [210] at index 0 does not match the shape of the indexed tensor [2] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lifted_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mPreProcessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m describe_data(lifted_dataset)\n",
      "File \u001b[0;32m~/Documents/Projects/Topo/challenge-icml-2024/tutorials/graph2hypergraph/../../modules/data/preprocess/preprocessor.py:32\u001b[0m, in \u001b[0;36mPreProcessor.__init__\u001b[0;34m(self, data_list, transforms_config, data_dir, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list \u001b[38;5;241m=\u001b[39m data_list\n\u001b[1;32m     31\u001b[0m pre_transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstantiate_pre_transform(data_dir, transforms_config)\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessed_data_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_transform_parameters()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_paths[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/topox/lib/python3.11/site-packages/torch_geometric/data/in_memory_dataset.py:81\u001b[0m, in \u001b[0;36mInMemoryDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     74\u001b[0m     root: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     force_reload: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     80\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data: Optional[BaseData] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Tensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/topox/lib/python3.11/site-packages/torch_geometric/data/dataset.py:115\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download()\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_process:\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/topox/lib/python3.11/site-packages/torch_geometric/data/dataset.py:260\u001b[0m, in \u001b[0;36mDataset._process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing...\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m    259\u001b[0m fs\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 260\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m path \u001b[38;5;241m=\u001b[39m osp\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre_transform.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    263\u001b[0m fs\u001b[38;5;241m.\u001b[39mtorch_save(_repr(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_transform), path)\n",
      "File \u001b[0;32m~/Documents/Projects/Topo/challenge-icml-2024/tutorials/graph2hypergraph/../../modules/data/preprocess/preprocessor.py:131\u001b[0m, in \u001b[0;36mPreProcessor.process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Process the data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list)\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Reset cache.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/Topo/challenge-icml-2024/tutorials/graph2hypergraph/../../modules/data/preprocess/preprocessor.py:131\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Process the data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list]\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list)\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Reset cache.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/topox/lib/python3.11/site-packages/torch_geometric/transforms/base_transform.py:32\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Shallow-copy the data so that we prevent in-place data modification.\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/topox/lib/python3.11/site-packages/torch_geometric/transforms/compose.py:24\u001b[0m, in \u001b[0;36mCompose.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     22\u001b[0m         data \u001b[38;5;241m=\u001b[39m [transform(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 24\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/topox/lib/python3.11/site-packages/torch_geometric/transforms/base_transform.py:32\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Shallow-copy the data so that we prevent in-place data modification.\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/Topo/challenge-icml-2024/tutorials/graph2hypergraph/../../modules/transforms/data_transform.py:75\u001b[0m, in \u001b[0;36mDataTransform.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: torch_geometric\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mData) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch_geometric\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mData:\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass of the lifting.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m        The lifted data.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/topox/lib/python3.11/site-packages/torch_geometric/transforms/base_transform.py:32\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Shallow-copy the data so that we prevent in-place data modification.\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/Topo/challenge-icml-2024/tutorials/graph2hypergraph/../../modules/transforms/liftings/lifting.py:62\u001b[0m, in \u001b[0;36mAbstractLifting.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the full lifting (topology + features) to the input data.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    The lifted data.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m initial_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[0;32m---> 62\u001b[0m lifted_topology \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlift_topology\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m lifted_topology \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_lifting(lifted_topology)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch_geometric\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mData(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minitial_data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlifted_topology)\n",
      "File \u001b[0;32m~/Documents/Projects/Topo/challenge-icml-2024/tutorials/graph2hypergraph/../../modules/transforms/liftings/graph2hypergraph/close_lifting.py:82\u001b[0m, in \u001b[0;36mHypergraphCloseLifting.lift_topology\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     78\u001b[0m data\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# data_lifted = self.transform(data)\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Find the closest nodes to each node\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m closest_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_close_res\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Now, I want to create hyperedges of the closest nodes\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Hyperedges = closest_nodes + edges\u001b[39;00m\n\u001b[1;32m     86\u001b[0m num_hyperedges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(closest_nodes) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39medge_index[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/Projects/Topo/challenge-icml-2024/tutorials/graph2hypergraph/../../modules/transforms/liftings/graph2hypergraph/close_lifting.py:58\u001b[0m, in \u001b[0;36mHypergraphCloseLifting.find_close_res\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     55\u001b[0m closest_nodes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_nodes):\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# Get the distances of the ith node\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     distances_i \u001b[38;5;241m=\u001b[39m \u001b[43mdistances\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# Get the indices of the closest nodes\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     closest_nodes_i \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(distances_i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistance)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [210] at index 0 does not match the shape of the indexed tensor [2] at index 0"
     ]
    }
   ],
   "source": [
    "lifted_dataset = PreProcessor(dataset, transform_config, loader.data_dir)\n",
    "describe_data(lifted_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Run a Cell NN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section a simple model is created to test that the used lifting works as intended. In this case the model uses the `x_0`, `x_1`, `x_2` which are the features of the nodes, edges and cells respectively. \n",
    "\n",
    "In QM9 dataset, there are 11 different features. That has been modified in the *dataset_config* file updating the correct number of features.\n",
    "\n",
    "It also uses the `adjacency_1`, `incidence_1` and `incidence_2` matrices so the lifting should make sure to add them to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model configuration for cell CWN:\n",
      "\n",
      "{'in_channels_0': None,\n",
      " 'in_channels_1': None,\n",
      " 'in_channels_2': None,\n",
      " 'hidden_channels': 32,\n",
      " 'out_channels': None,\n",
      " 'n_layers': 2}\n"
     ]
    }
   ],
   "source": [
    "from modules.models.cell.cwn import CWNModel\n",
    "\n",
    "model_type = \"cell\"\n",
    "model_id = \"cwn\"\n",
    "model_config = load_model_config(model_type, model_id)\n",
    "\n",
    "model = CWNModel(model_config, dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model(lifted_dataset.get(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything is correct the cell above should execute without errors. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_topox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
